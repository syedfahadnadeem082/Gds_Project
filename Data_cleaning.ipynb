{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d9969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Author ID               Author Name  \\\n",
      "0    39481716                  m. corry   \n",
      "1  1400383433  catalina amuedo-dorantes   \n",
      "2     4059419            cynthia bansak   \n",
      "3    40392273                susan pozo   \n",
      "4    47693041                 g. myrdal   \n",
      "\n",
      "                                          Author URL  \n",
      "0    https://www.semanticscholar.org/author/39481716  \n",
      "1  https://www.semanticscholar.org/author/1400383433  \n",
      "2     https://www.semanticscholar.org/author/4059419  \n",
      "3    https://www.semanticscholar.org/author/40392273  \n",
      "4    https://www.semanticscholar.org/author/47693041  \n"
     ]
    }
   ],
   "source": [
    "# Cleaning author (1).txt file and converting to csv.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (you can load from your .txt or .csv file)\n",
    "file_path = 'author (1).txt'\n",
    "author_df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicate rows\n",
    "author_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove rows with any null values\n",
    "author_df.dropna(inplace=True)\n",
    "\n",
    "# Optionally, reset the index after dropping rows\n",
    "author_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "author_df.to_csv('cleaned_author_data.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(author_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54aa32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Author ID                                  Paper ID\n",
      "0    13549554  0d956c858ee99bf830e816fe446da13f86e0b020\n",
      "1   120815555  81904327e0501907a0c7a364c592fdf984a7812c\n",
      "2     4965059  e3e1bdf96e23151eff6adadada0c71b474dede49\n",
      "3   144136549  f88f63e399f8d60fc25f673e2dad09ac6bf25146\n",
      "4  1667729458  98d47bbcb0f419f2245f9c53def4be523763e4d4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with the actual path to your file)\n",
    "file_path = 'author_paper.txt'\n",
    "author_paper_df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove duplicate rows (based on both Author ID and Paper ID)\n",
    "author_paper_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove rows with any null values in Author ID or Paper ID columns\n",
    "author_paper_df.dropna(subset=['Author ID', 'Paper ID'], inplace=True)\n",
    "\n",
    "# Optionally, reset the index after cleaning\n",
    "author_paper_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "author_paper_df.to_csv('cleaned_author_paper.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(author_paper_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6967893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Journal Name  \\\n",
      "1  Journal of Immigrant and Refugee Studies   \n",
      "2                                Identities   \n",
      "3                 Ethnic and Racial Studies   \n",
      "7       Asian and Pacific Migration Journal   \n",
      "8   Journal of Ethnic and Migration Studies   \n",
      "\n",
      "                               Journal Publisher  \n",
      "1                      Routledgeinfo@tandf.co.uk  \n",
      "2                        Taylor and Francis Ltd.  \n",
      "3                                      Routledge  \n",
      "7  Scalabrini Migration Centerclaims@sagepub.com  \n",
      "8                      Routledgeinfo@tandf.co.uk  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with the actual path to your file)\n",
    "file_path = 'journal.txt'\n",
    "journal_df = pd.read_csv(file_path, header=None, names=['Journal Name', 'Journal Publisher'])\n",
    "\n",
    "# Remove any surrounding quotes (\"\") from the Journal Name and Journal Publisher columns using regex\n",
    "#journal_df['Journal Name'] = journal_df['Journal Name'].str.replace(r'\"', '', regex=True).str.strip()\n",
    "#journal_df['Journal Publisher'] = journal_df['Journal Publisher'].str.replace(r'\"', '', regex=True).str.strip()\n",
    "#journal_df['Journal Name'] = journal_df['Journal Name'].str.replace('\"', '', regex=False) # For double quotes\n",
    "#journal_df['Journal Publisher'] = journal_df['Journal Publisher'].str.replace(\"'\", '', regex=False) # For single quotes\n",
    "# Split the 'Journal Publisher' column by commas if there are multiple publishers\n",
    "journal_df['Journal Publisher'] = journal_df['Journal Publisher'].str.split(',')\n",
    "journal_df = journal_df.explode('Journal Publisher')\n",
    "\n",
    "# Remove any extra whitespace in the 'Journal Publisher' and 'Journal Name' columns\n",
    "journal_df['Journal Publisher'] = journal_df['Journal Publisher'].str.strip()\n",
    "journal_df['Journal Name'] = journal_df['Journal Name'].str.strip()\n",
    "\n",
    "# Remove duplicate rows (where both 'Journal Name' and 'Journal Publisher' are the same)\n",
    "journal_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove any rows where 'Journal Publisher' is NaN or empty\n",
    "journal_df.dropna(subset=['Journal Publisher'], inplace=True)\n",
    "journal_df = journal_df.drop(0) \n",
    "# Save the cleaned data to a new file\n",
    "journal_df.to_csv('cleaned_journal_data.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(journal_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae52adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\2908325946.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  paper_journal_df['Journal Publisher'].fillna('Not Published', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                   Paper ID  \\\n",
       " 1  4301e6749a626fe36567e53f49fa5a247ba28dd7   \n",
       " 2  2c84d9e3c279717276f85352970a12b2c318fa6e   \n",
       " 3  e80d8babbb18afbdc4ac3ccd5d19b578d790a94e   \n",
       " 4  2540253d3503a06adac372dda2883d8cd7731be6   \n",
       " 5  66e1fc7f5c8cef3b094d8539d308a8724ea72291   \n",
       " \n",
       "                                         Journal Name  \\\n",
       " 1            Journal of Ethnic and Migration Studies   \n",
       " 2                           Journal of Black Studies   \n",
       " 3                              Patterns of Prejudice   \n",
       " 4  International Journal of Migration, Health and...   \n",
       " 5                                         Mobilities   \n",
       " \n",
       "            Journal Publisher  \n",
       " 1  Routledgeinfo@tandf.co.uk  \n",
       " 2              Not Published  \n",
       " 3              Not Published  \n",
       " 4              Not Published  \n",
       " 5  Routledgeinfo@tandf.co.uk  ,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning paper_journal.txt\n",
    "# Re-import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file again (paper_journal.txt) to clean\n",
    "file_path_paper_journal = 'paper_journal.txt'\n",
    "\n",
    "# Load the dataset (no header row since it is part of the data itself)\n",
    "paper_journal_df = pd.read_csv(file_path_paper_journal, header=None, names=['Paper ID', 'Journal Name', 'Journal Publisher'])\n",
    "\n",
    "# Remove duplicate rows (where both 'Journal Name' and 'Journal Publisher' are the same)\n",
    "paper_journal_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Replace any missing or empty values in 'Journal Publisher' with 'Not Published'\n",
    "paper_journal_df['Journal Publisher'].fillna('Not Published', inplace=True)\n",
    "\n",
    "# Replace any blank spaces in the 'Journal Publisher' column with 'Not Published'\n",
    "#paper_journal_df['Journal Publisher'] = paper_journal_df['Journal Publisher'].replace('', 'Not Published')\n",
    "\n",
    "# Trim any leading/trailing spaces from both 'Journal Name' and 'Journal Publisher' columns\n",
    "paper_journal_df['Journal Name'] = paper_journal_df['Journal Name'].str.strip()\n",
    "paper_journal_df['Journal Publisher'] = paper_journal_df['Journal Publisher'].str.strip()\n",
    "paper_journal_df['Paper ID'] = paper_journal_df['Paper ID'].str.strip()\n",
    "paper_journal_df = paper_journal_df.drop(0)\n",
    "# Save the cleaned data to a new file\n",
    "#cleaned_paper_journal_file_path = '/mnt/data/cleaned_paper_journal_data_no_split.csv'\n",
    "paper_journal_df.to_csv('cleaned_paper_journal.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "paper_journal_df.head(), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fe1f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\1059708315.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  paper_reference_df['Referenced Paper ID'].fillna('No reference', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                   Paper ID  \\\n",
       " 1  61947b0f3397247c43f75cf7b155651c463ae335   \n",
       " 2  92fd5a378f9188503f34b99d423646afa99c8789   \n",
       " 3  6e8db759eed9b7a7ae2de194e22c727f44f91809   \n",
       " 4  29dbf7509867acd7bd20d8bb0d96e97f4999cc87   \n",
       " 5  6602bd956a04eaf12397df89a25cf1257e067da6   \n",
       " \n",
       "                         Referenced Paper ID  \n",
       " 1  b87c108607688fe11b8cfe0b1374efcaa52f8c8e  \n",
       " 2  25344b0e9215e4b32b5d72e229e4b54f1b532f21  \n",
       " 3  46d44a00406185ba54913ec58ccf7c4e1497f7a2  \n",
       " 4  f06f633b1b30bc681fd8e73e94447e1a6f285aab  \n",
       " 5                               paper180540  ,\n",
       " 'cleaned_paper_reference.csv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean paper_reference.txt\n",
    "\n",
    "# Re-import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded paper_reference.txt data to clean\n",
    "file_path_paper_reference = 'paper_reference.txt'\n",
    "\n",
    "# Load the dataset (no header row since it is part of the data itself)\n",
    "paper_reference_df = pd.read_csv(file_path_paper_reference, header=None, names=['Paper ID', 'Referenced Paper ID'])\n",
    "\n",
    "# Remove duplicate rows (where both 'Paper ID' and 'Referenced Paper ID' are the same)\n",
    "paper_reference_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Replace any missing or empty values in 'Referenced Paper ID' with 'Not Available'\n",
    "paper_reference_df['Referenced Paper ID'].fillna('No reference', inplace=True)\n",
    "\n",
    "# Replace any blank spaces in the 'Referenced Paper ID' column with 'Not Available'\n",
    "paper_reference_df['Referenced Paper ID'] = paper_reference_df['Referenced Paper ID'].replace('', 'No reference')\n",
    "\n",
    "# Trim any leading/trailing spaces from both 'Paper ID' and 'Referenced Paper ID' columns\n",
    "paper_reference_df['Paper ID'] = paper_reference_df['Paper ID'].str.strip()\n",
    "paper_reference_df['Referenced Paper ID'] = paper_reference_df['Referenced Paper ID'].str.strip()\n",
    "paper_reference_df = paper_reference_df.drop(0)\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_paper_reference_file_path = 'cleaned_paper_reference.csv'\n",
    "paper_reference_df.to_csv(cleaned_paper_reference_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "paper_reference_df.head(), cleaned_paper_reference_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b709104f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                    Paper ID Topic ID\n",
       " 5   d805fa042d37aa462d22026acf9d5e51d09dfe79   555092\n",
       " 11  f0d0b7bc4e2e8efe25a0fcec4f1790486660c2d4   155706\n",
       " 19  b0336575e305e1d6bbc40d0de7fcb01f2d88393e  4083837\n",
       " 20  f6b5dac39b8258728a047ec4f6442b571094eb9f   269965\n",
       " 23  d0058915656420ad3b90a0e20557baae4bf35ee8     9734,\n",
       " 'cleaned_paper_topic.csv')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning paper_topic.txt\n",
    "# Re-import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded paper_topic.txt data to clean\n",
    "file_path_paper_topic = 'paper_topic.txt'\n",
    "\n",
    "# Load the dataset (no header row since it is part of the data itself)\n",
    "paper_topic_df = pd.read_csv(file_path_paper_topic, header=None, names=['Paper ID', 'Topic ID'])\n",
    "\n",
    "# Remove duplicate rows where both 'Paper ID' and 'Topic ID' are the same\n",
    "paper_topic_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove rows where 'Topic ID' is repeated (Topic ID should be unique)\n",
    "paper_topic_df = paper_topic_df.drop_duplicates(subset=['Topic ID'], keep=False)\n",
    "\n",
    "# Trim any leading/trailing spaces from both 'Paper ID' and 'Topic ID' columns\n",
    "paper_topic_df['Paper ID'] = paper_topic_df['Paper ID'].str.strip()\n",
    "paper_topic_df['Topic ID'] = paper_topic_df['Topic ID'].str.strip()\n",
    "paper_topic_df = paper_topic_df.drop(0)\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_paper_topic_file_path = 'cleaned_paper_topic.csv'\n",
    "paper_topic_df.to_csv(cleaned_paper_topic_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "paper_topic_df.head(), cleaned_paper_topic_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa87d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\4163776812.py:7: DtypeWarning: Columns (3,5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\4163776812.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                    Paper ID  \\\n",
       " 6   0b080d5b56bab6e8ea7049352b60dae260774a10   \n",
       " 7   65c3428a169981aedfd8578e940c0963cab4115e   \n",
       " 8   9e4e8c2dfa0e2889cee72a994a9136ab8af10d13   \n",
       " 22  839d330ae9ba9b7ad58cdfa324d7a6426bf96131   \n",
       " 28  d3665ffeb9171ed210ec3c6c63a12f90d5b6cc8b   \n",
       " \n",
       "                              Paper DOI  \\\n",
       " 6           10.1177/030639686200400101   \n",
       " 7   10.1111/j.1468-2435.1965.tb00735.x   \n",
       " 8           10.1177/030639685900100207   \n",
       " 22          10.1177/030639685900100203   \n",
       " 28          10.1177/030639685900100202   \n",
       " \n",
       "                                           Paper Title  Paper Year  \\\n",
       " 6                                 an american dilemma      1944.0   \n",
       " 7               the world population conference, 1954      1955.0   \n",
       " 8             some greek stereotypes of other peoples      1959.0   \n",
       " 22    a recent west indian immigrant group in britain      1959.0   \n",
       " 28  applied social science and public policy conce...      1959.0   \n",
       " \n",
       "                                             Paper URL  Paper Citation Count  \\\n",
       " 6   https://www.semanticscholar.org/paper/0b080d5b...                   3.0   \n",
       " 7   https://www.semanticscholar.org/paper/65c3428a...                   0.0   \n",
       " 8   https://www.semanticscholar.org/paper/9e4e8c2d...                   0.0   \n",
       " 22  https://www.semanticscholar.org/paper/839d330a...                   2.0   \n",
       " 28  https://www.semanticscholar.org/paper/d3665ffe...                   1.0   \n",
       " \n",
       "       Fields of Study  Journal Volume Journal Date  \n",
       " 6           Sociology             4.0   1962-01-01  \n",
       " 7    Computer Science             3.0   1965-01-01  \n",
       " 8             History             1.0   1959-01-01  \n",
       " 22          Sociology             1.0   1959-01-01  \n",
       " 28  Political Science             1.0   1959-01-01  ,\n",
       " 'cleaned_paper.csv')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning paper.txt\n",
    "\n",
    "# Load the uploaded paper.txt data to clean\n",
    "file_path_paper = 'paper.txt'\n",
    "\n",
    "# Load the dataset (no header row since it is part of the data itself)\n",
    "paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
    "\n",
    "# Remove duplicate rows based on all columns\n",
    "paper_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Ensure that 'Paper ID', 'Paper DOI', 'Paper Title', and 'Paper URL' are unique\n",
    "paper_df = paper_df.drop_duplicates(subset=['Paper ID'], keep=False)  # Remove any duplicate Paper IDs\n",
    "paper_df = paper_df.drop_duplicates(subset=['Paper DOI'], keep=False)  # Remove any duplicate Paper DOIs\n",
    "paper_df = paper_df.drop_duplicates(subset=['Paper Title'], keep=False)  # Remove any duplicate Paper Titles\n",
    "paper_df = paper_df.drop_duplicates(subset=['Paper URL'], keep=False)  # Remove any duplicate Paper URLs\n",
    "# Drop rows where any of the numeric columns have NaN values\n",
    "paper_df.dropna(subset=['Paper Year', 'Paper Citation Count', 'Journal Volume'], inplace=True)\n",
    "# Convert 'Paper Year', 'Paper Citation Count', and 'Journal Volume' to integers\n",
    "#paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], errors='coerce', downcast='integer')\n",
    "#paper_df['Paper Citation Count'] = pd.to_numeric(paper_df['Paper Citation Count'], errors='coerce', downcast='integer')\n",
    "#paper_df['Journal Volume'] = pd.to_numeric(paper_df['Journal Volume'], errors='coerce', downcast='integer')\n",
    "#paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n",
    "# Convert 'Paper Year', 'Paper Citation Count', and 'Journal Volume' to integers and drop rows with invalid values\n",
    "paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], errors='coerce')  # Convert to numeric, invalid values become NaN\n",
    "paper_df['Paper Citation Count'] = pd.to_numeric(paper_df['Paper Citation Count'], errors='coerce')\n",
    "paper_df['Journal Volume'] = pd.to_numeric(paper_df['Journal Volume'], errors='coerce')\n",
    "\n",
    "\n",
    "# Convert 'Journal Date' to datetime and drop rows with invalid dates\n",
    "paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where the 'Journal Date' is invalid (NaT = Not a Time)\n",
    "paper_df.dropna(subset=['Journal Date'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_paper_file_path = 'cleaned_paper.csv'\n",
    "paper_df.to_csv(cleaned_paper_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "paper_df.head(), cleaned_paper_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca4451bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\2283875868.py:6: DtypeWarning: Columns (3,5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\2283875868.py:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Paper ID                        object\n",
       "Paper DOI                       object\n",
       "Paper Title                     object\n",
       "Paper Year                     float64\n",
       "Paper URL                       object\n",
       "Paper Citation Count           float64\n",
       "Fields of Study                 object\n",
       "Journal Volume                 float64\n",
       "Journal Date            datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path_paper = 'paper.txt'  # Replace with the actual path\n",
    "\n",
    "paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
    "\n",
    "# Convert 'Paper Year', 'Paper Citation Count', and 'Journal Volume' to numeric types (integers)\n",
    "#paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], errors='coerce')\n",
    "paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], downcast='integer', errors='coerce')\n",
    "paper_df['Paper Citation Count'] = pd.to_numeric(paper_df['Paper Citation Count'], errors='coerce')\n",
    "paper_df['Journal Volume'] = pd.to_numeric(paper_df['Journal Volume'], errors='coerce')\n",
    "\n",
    "# Convert 'Journal Date' to datetime, invalid dates will be converted to NaT (Not a Time)\n",
    "paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where any of the specified columns are NaN (invalid data)\n",
    "paper_df.dropna(subset=['Paper Year', 'Paper Citation Count', 'Journal Volume', 'Journal Date'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "paper_df = paper_df.dropna()\n",
    "cleaned_paper_file_path = 'cleaned_paper.csv'\n",
    "paper_df.to_csv(cleaned_paper_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "#paper_df.head(), cleaned_paper_file_path\n",
    "#paper_df.isnull().sum()\n",
    "\n",
    "paper_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10c02342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\1517343826.py:5: DtypeWarning: Columns (3,5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_13448\\1517343826.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Paper ID                        object\n",
       "Paper DOI                       object\n",
       "Paper Title                     object\n",
       "Paper Year                     float64\n",
       "Paper URL                       object\n",
       "Paper Citation Count           float64\n",
       "Fields of Study                 object\n",
       "Journal Volume                 float64\n",
       "Journal Date            datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path_paper = 'paper.txt'  # Replace with the actual file path\n",
    "paper_df = pd.read_csv(file_path_paper, header=None, names=['Paper ID', 'Paper DOI', 'Paper Title', 'Paper Year', 'Paper URL', 'Paper Citation Count', 'Fields of Study', 'Journal Volume', 'Journal Date'])\n",
    "\n",
    "# Convert 'Paper Year', 'Paper Citation Count', and 'Journal Volume' to numeric types (integers)\n",
    "paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], errors='coerce')  # Invalid values become NaN\n",
    "paper_df['Paper Citation Count'] = pd.to_numeric(paper_df['Paper Citation Count'], errors='coerce')\n",
    "paper_df['Journal Volume'] = pd.to_numeric(paper_df['Journal Volume'], errors='coerce')\n",
    "\n",
    "# Convert 'Journal Date' to datetime, invalid entries like 'XXXX' will be coerced to NaT\n",
    "paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where any of the specified columns have NaN or NaT values (invalid data)\n",
    "paper_df.dropna(subset=['Paper Year', 'Paper Citation Count', 'Journal Volume', 'Journal Date'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_paper_file_path = 'cleaned_paper_data_valid_rows.csv'\n",
    "paper_df.to_csv(cleaned_paper_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "#paper_df.head(), cleaned_paper_file_path\n",
    "paper_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e1318",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Check for any rows with garbage values (e.g., empty or invalid fields in 'Fields of Study' or 'Paper DOI')\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Remove rows where 'Fields of Study' or 'Paper DOI' are empty or null\u001b[39;00m\n\u001b[0;32m     26\u001b[0m paper_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields of Study\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPaper DOI\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43mpaper_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Save the cleaned data to a new file\u001b[39;00m\n\u001b[0;32m     29\u001b[0m cleaned_paper_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_paper_data_valid_rows_.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# Re-import pandas and load the uploaded dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace with the actual file path)\n",
    "file_path = 'cleaned_paper.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "paper_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "paper_df.head()\n",
    "\n",
    "# Convert 'Paper Year', 'Paper Citation Count', and 'Journal Volume' to numeric types, invalid values become NaN\n",
    "paper_df['Paper Year'] = pd.to_numeric(paper_df['Paper Year'], errors='coerce')\n",
    "paper_df['Paper Citation Count'] = pd.to_numeric(paper_df['Paper Citation Count'], errors='coerce')\n",
    "paper_df['Journal Volume'] = pd.to_numeric(paper_df['Journal Volume'], errors='coerce')\n",
    "\n",
    "# Convert 'Journal Date' to datetime, invalid entries like '#####' will be coerced to NaT\n",
    "paper_df['Journal Date'] = pd.to_datetime(paper_df['Journal Date'], errors='coerce')\n",
    "\n",
    "# Drop rows where any of the specified columns have NaN or NaT (invalid data)\n",
    "paper_df.dropna(subset=['Paper Year', 'Paper Citation Count', 'Journal Volume', 'Journal Date'], inplace=True)\n",
    "\n",
    "# Check for any rows with garbage values (e.g., empty or invalid fields in 'Fields of Study' or 'Paper DOI')\n",
    "# Remove rows where 'Fields of Study' or 'Paper DOI' are empty or null\n",
    "paper_df.dropna(subset=['Fields of Study', 'Paper DOI'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_paper_file_path = 'cleaned_paper_data_valid_rows_.csv'\n",
    "paper_df.to_csv(cleaned_paper_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "#paper_df.head(), cleaned_paper_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fda9c872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Topic ID          Topic Name                                      Topic URL\n",
       " 1   365920         corrigendum   https://www.semanticscholar.org/topic/365920\n",
       " 2     2460              Volume     https://www.semanticscholar.org/topic/2460\n",
       " 3  4169797      latin language  https://www.semanticscholar.org/topic/4169797\n",
       " 4   639351            CONQUEST   https://www.semanticscholar.org/topic/639351\n",
       " 5    20266  Reading (activity)    https://www.semanticscholar.org/topic/20266,\n",
       " 'cleaned_topic.csv')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning topic.txt\n",
    "\n",
    "# Load the uploaded topic.txt data to clean\n",
    "file_path_topic = 'topic.txt'\n",
    "\n",
    "# Load the dataset (no header row since it is part of the data itself)\n",
    "topic_df = pd.read_csv(file_path_topic, header=None, names=['Topic ID', 'Topic Name', 'Topic URL'])\n",
    "\n",
    "# Remove duplicate rows based on 'Topic ID' and 'Topic URL'\n",
    "topic_df.drop_duplicates(subset=['Topic ID', 'Topic URL'], keep='first', inplace=True)\n",
    "\n",
    "# Trim any leading/trailing spaces from 'Topic Name' and 'Topic URL' columns\n",
    "topic_df['Topic Name'] = topic_df['Topic Name'].str.strip()\n",
    "topic_df['Topic URL'] = topic_df['Topic URL'].str.strip()\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "cleaned_topic_file_path = 'cleaned_topic.csv'\n",
    "topic_df = topic_df.drop(0)\n",
    "topic_df.to_csv(cleaned_topic_file_path, index=False)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "topic_df.head(), cleaned_topic_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
